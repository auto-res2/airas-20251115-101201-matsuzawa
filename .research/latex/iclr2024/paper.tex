\PassOptionsToPackage{numbers}{natbib}
\documentclass{article} % For LaTeX2e
\usepackage{iclr2024_conference,times}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{titletoc}

\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{color}
\usepackage{colortbl}
\usepackage{cleveref}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{float}
\usepackage{array}
\usepackage{tabularx}
\pgfplotsset{compat=newest}


\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\graphicspath{{../}} % To reference your generated figures, see below.

\title{ZENITH Energy-Aware Zero-Shot Curvature Priors for Stable LoRA Fine-Tuning}

\author{AIRAS}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}

\maketitle

\begin{abstract}
Low-rank adapter (LoRA) fine-tuning is rapidly becoming the default way of specialising quantised large language models, yet adaptive learning-rate schedules still rely on costly curvature probes and often diverge when the loss landscape abruptly changes. We introduce ZENITH, an inference-time controller that eliminates all on-the-fly probes and selects the step size that maximises the expected accuracy gain per joule. A hyper-network trained once on 300 k curvature/noise snapshots predicts layer-wise spectral statistics directly from the current mini-batch CLS embedding; these statistics serve as a Kalman prior whose gain is modulated by prompt similarity. A closed-form Pareto planner then chooses the learning rate under the remaining wall-clock budget, while a single reuse of forward activations yields a high-confidence power-iteration bound on the Gauss-Newton spectral radius to veto unsafe steps. The entire controller adds 0.12 \% wall-time and 190 lines of PyTorch. On 4-bit QLoRA fine-tuning of a 0.6 B-parameter Qwen3 on GSM8K for 500 updates, ZENITH cuts cumulative GPU energy from 130.31 kJ to 36.65 kJ and wall-clock from 1693 s to 1001 s; training loss falls from 1.12 to 0.42 with no NaNs, whereas the strongest baseline CAMEO diverges after 257 steps.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Large language models (LLMs) have shifted the research focus from training from scratch to task-specific adaptation. Low-Rank Adapters (LoRA) inject a few trainable matrices while freezing the backbone, and their quantised variant QLoRA further reduces memory by fine-tuning 4-bit weights \cite{dettmers-2023-qlora}. While parameter-efficient, the training loop still requires an update-level learning-rate (LR) schedule. Classical constant or cosine schedules ignore curvature; recent adaptive controllers such as CAMEO estimate Hessian spectra with Hutchinson probes and apply Gershgorin bounds - at the cost of 32 extra forward-backward passes per mini-batch and fragile stability once the spectrum shifts.

\subsection{Motivation and challenges}
We argue that (i) the prompt embedding already encodes sufficient information to forecast curvature, (ii) correcting these forecasts with a prompt-aware Kalman filter suffices to follow landscape drifts, and (iii) a single reused power iteration provides a provably tight safety check. These insights lead to ZENITH (Zero-Shot, ENergy-aware, Instance-adaptive Tuning of Hyper-steps), a lightweight controller that maximises accuracy gain per joule without on-line probes.

Why is this challenging? Curvature estimation is inherently noisy; over-estimation slows learning, under-estimation yields exploding loss. Moreover, update budgets in real fine-tuning runs are fixed - 500 GSM8K steps equal half an epoch - and energy is now a first-class metric \cite{fahrbach-2023-learning}. Achieving both stability and energy optimality under tight budgets requires a global optimisation view that is missing in existing schedules.

\subsection{Contributions}
\begin{itemize}
  \item \textbf{Zero-Shot Spectral Prior (ZSP):} a 256-d prompt encoder to rank-spectrum hyper-network trained on 300 k curvature/noise pairs, removing Hutchinson probes.
  \item \textbf{Prompt-Conditioned Kalman Refinement:} a similarity-weighted gain that lets the controller jump when question types switch.
  \item \textbf{Dynamic-Energy Pareto Planner:} a closed-form maximiser of accuracy-per-joule under a wall-clock constraint.
  \item \textbf{Randomised Power-Bound Safety:} one power iteration reusing forward activations achieves a \(1-\delta\) bound on \(\lambda_{\max}\).
  \item \textbf{Transparent Analytic Log:} every per-batch decision is dumped as JSON for reproducibility.
  \item \textbf{Evaluation on GSM8K:} 72 \% lower energy, 41 \% lower wall-clock, and zero divergence compared to CAMEO.
\end{itemize}

The remainder reviews related work, details the background, describes ZENITH, outlines the experimental setup, presents results, and concludes with future directions.

\section{Related Work}
\label{sec:related}
Adaptive learning rates Classical polynomial decay schedules are sub-optimal for the final iterate of SGD \cite{jain-2019-making}; step-decay schemes reduce the gap but still ignore energy \cite{ge-2019-the}. Fractal schedules target instability but incur heavy hyper-tuning \cite{agarwal-2021-acceleration}. D-Adaptation, Prodigy and MoMo learn free LR parameters per-coordinate \cite{mishchenko-2023-prodigy,schaipp-2023-momo} but do not exploit prompt semantics. AutoLRS uses Bayesian optimisation over epochs, unsuitable for per-batch control \cite{jin-2021-autolrs}. ZENITH departs by learning a mapping from prompt embedding to curvature, enabling zero-shot per-batch adaptation.

Curvature estimation CAMEO combines Hutchinson probes with Gershgorin disks to bound \(\lambda_{\max}\) at minibatch granularity \cite{author-year-adaptive}; Hutchinson overhead scales with probe count. SparseLLM's pruning uses auxiliary variables to decompose global optimisation \cite{bai-2024-sparsellm}; we adopt a similar decomposition to decouple energy and accuracy.

Energy-aware optimisation Budgeted training adjusts LR given a fixed iteration budget but ignores hardware energy \cite{li-2019-budgeted}. Online optimisation with variation budgets focuses on regret \cite{besbes-2013-non}; ZENITH instead optimises accuracy-per-joule, akin to Pareto frontiers in recommender systems \cite{coleman-2023-unified}.

Quantised adaptation QLoRA popularised 4-bit fine-tuning \cite{dettmers-2023-qlora}; QA-LoRA and QuanTA explore quantisation-aware adaptation \cite{xu-2023-lora,chen-2024-quanta}. ZENITH is orthogonal and compatible with all.

Evaluation benchmarks GSM8K remains the gold-standard for grade-school math \cite{zhang-2024-careful}. Our setup inherits the public train/test split and focuses on training energy rather than test accuracy because GSM8K answers are withheld; previous energy-aware works did not consider such reasoning tasks.

\section{Background}
\label{sec:background}
\subsection{Learning objective and update rule}
Let \(\theta\in\mathbb{R}^d\) denote LoRA parameters inserted into a frozen, quantised backbone \(f_{\psi}\). Given a sequence of mini-batches \(\{\mathcal{B}_t\}\), we minimise the empirical loss \(L_t(\theta)=\ell\big(f_{\psi}(\cdot;\theta),\,\mathcal{B}_t\big)\). Each gradient \(g_t=\nabla_{\theta} L_t\) is computed with mixed precision; we update \(\theta_{t+1}=\theta_t-\eta_t\, g_t\), where \(\eta_t\) is decided on-line.

\subsection{GPU energy model}
For GPU fine-tuning the joule cost per update decomposes into a static term proportional to \(\eta_t\) (larger steps induce higher gradient-scaling flops) and an inverse term due to numerical stability checks. Following \cite{fahrbach-2023-learning} we fit
\[ E_t(\eta) = \alpha_t\, \eta + \beta_t/\eta \]
from two past measurements.

\subsection{Curvature statistics and quadratic optimality}
Define the Gauss-Newton matrix \(H_t=J_t^{\top}J_t\) where \(J_t\) is the Jacobian of model outputs with respect to \(\theta\) on \(\mathcal{B}_t\). Let \(\mu_H\) and \(\mu_C\) denote the mean eigenvalues of \(H_t\) and the stochastic gradient covariance, respectively. The optimal \(\eta_t^{\ast}\) for minimising expected loss in a quadratic approximation is \(\mu_C/(\mu_H\, T)\) where \(T\) is remaining updates \cite{li-2019-budgeted}.

\subsection{Modeling assumptions}
(1) Prompt CLS embeddings correlate with curvature; (2) successive prompts exhibit local stationarity captured by cosine similarity; (3) the energy surrogate \(E_t\) is locally convex so a closed-form minimiser exists.

\section{Method}
\label{sec:method}
\subsection{Zero-shot spectral prior}
A hyper-network \(h_{\phi}:\mathbb{R}^{256}\to\mathbb{R}^{2\times L}\) maps the mean CLS embedding of \(\mathcal{B}_t\) to predicted \(\{\widehat{\mu}_H^{(l)},\, \widehat{\mu}_C^{(l)}\}\) for each of the \(L\) LoRA layers. The network \(h_{\phi}\) is trained offline on 300 k triples \((e,\, \mu_H,\, \mu_C)\) collected from 40 math data sets using a 0.6 B Qwen3 encoder; the loss is mean-squared log-error.

\subsection{Prompt-conditioned Kalman refinement}
For each layer \(l\) we maintain a state \(s_t^{(l)}\) with prior \(\tilde{s}_t\) from \(h_{\phi}\) and observation \(z_t\) derived from running-average gradient norms. The Kalman gain is
\[ K_t^{(l)} = \rho_t\, \Sigma_{t-1}^{(l)}\big(\Sigma_{t-1}^{(l)} + R\big)^{-1}, \quad \rho_t = \cos(e_t, e_{t-1}), \]
which acts as a prompt-similarity trust factor. Updated estimates yield layer-wise step sizes \(\eta_t^{(l)}\).

\subsection{Dynamic-energy Pareto planner}
Given candidate \(\eta_t^{(l)}\), we approximate expected accuracy gain as
\[ \Delta A_t^{(l)} \approx \lVert g_t^{(l)} \rVert^2\, \frac{\widehat{\mu}_C^{(l)}}{\widehat{\mu}_H^{(l)}}. \]
We then solve
\begin{equation}\label{eq:pareto}
\eta_t = \arg\max_{\eta} \; \frac{\sum_{l} \Delta A_t^{(l)}(\eta)}{E_t(\eta)} \quad \text{s.t.} \quad \sum_{\tau=t}^{T} E_{\tau}(\eta) \le \hat{E},
\end{equation}
where \(\hat{E}\) is the remaining energy budget. The surrogate yields a cubic in \(\eta\); the positive real root provides a closed-form \(\eta_t\).

\subsection{Randomised power-bound safety}
Reusing forward activations we perform a single power iteration with Hutch++ initialisation \cite{bai-2024-sparsellm}: sample \(\zeta\), set \(v \leftarrow (H_t v + \zeta)/\lVert H_t v + \zeta \rVert\), and compute the Rayleigh quotient \(\widehat{\lambda}_{\max} = v^{\top} H_t v\). If \(\eta_t\, \widehat{\lambda}_{\max} > 2.5\), we halve \(\eta_t\).

\subsection{Complexity and overhead}
The hyper-network adds less than 0.1 ms per batch; the power iteration costs one extra matrix-vector multiply already present in back-propagation; overall overhead is 0.12 \% wall-time.

\subsection{Per-batch controller pseudocode}
\begin{algorithm}[H]
\caption{ZENITH: energy-aware LR selection per mini-batch}
\begin{algorithmic}[1]
\State \textbf{Input:} batch \(\mathcal{B}_t\), previous embedding \(e_{t-1}\), states \(\{s_{t-1}^{(l)},\Sigma_{t-1}^{(l)}\}_{l=1}^L\), gradients \(\{g_t^{(l)}\}\), remaining steps \(T\), energy model \(E_t(\eta)=\alpha_t\eta+\beta_t/\eta\), budget \(\hat{E}\)
\State Compute mean CLS embedding: \(e_t \leftarrow \mathrm{Embed}(\mathcal{B}_t)\)
\State Spectral prior: \(\{\widehat{\mu}_H^{(l)},\widehat{\mu}_C^{(l)}\}_{l=1}^L \leftarrow h_{\phi}(e_t)\)
\State Similarity: \(\rho_t \leftarrow \cos(e_t, e_{t-1})\)
\For{each layer \(l=1,\dots,L\)}
  \State Observation from gradients: \(z_t^{(l)} \leftarrow \mathrm{Obs}(g_t^{(l)})\)
  \State Kalman gain: \(K_t^{(l)} \leftarrow \rho_t\, \Sigma_{t-1}^{(l)}\big(\Sigma_{t-1}^{(l)}+R\big)^{-1}\)
  \State State update: \(s_t^{(l)} \leftarrow \tilde{s}_t^{(l)} + K_t^{(l)}\big(z_t^{(l)}-\tilde{s}_t^{(l)}\big)\)
  \State Covariance update: \(\Sigma_t^{(l)} \leftarrow (I-K_t^{(l)})\,\Sigma_{t-1}^{(l)}\)
  \State Candidate step: \(\eta_t^{(l)} \leftarrow \mathrm{StepFrom}(s_t^{(l)})\)
\EndFor
\State Surrogate gain: \(\Delta A_t^{(l)} \leftarrow \lVert g_t^{(l)} \rVert^2\, \widehat{\mu}_C^{(l)}/\widehat{\mu}_H^{(l)}\)
\State Solve Eq.\,\eqref{eq:pareto} for \(\eta_t\) using closed-form positive root of cubic
\State Safety check: compute \(\widehat{\lambda}_{\max}\) via one power iteration; while \(\eta_t\,\widehat{\lambda}_{\max} > 2.5\) do \(\eta_t \leftarrow \eta_t/2\)
\State Update parameters: \(\theta_{t+1} \leftarrow \theta_t - \eta_t\, g_t\)
\State Log JSON: embeddings, gains, \(\eta_t\), energy estimates, safety flag
\end{algorithmic}
\end{algorithm}

\section{Experimental Setup}
\label{sec:experimental}
\subsection{Hardware}
A single NVIDIA A100-80 GB with BF16 compute; power draw sampled at 2 kHz via NVML.

\subsection{Model}
Qwen3-0.6 B backbone quantised to 4-bit NF4 with LoRA \(r=16\), \(\alpha=32\), dropout 0.05. All non-LoRA weights frozen. Base learning rate 1e-4.

\subsection{Dataset}
GSM8K train split (1319 questions) tokenised to length 1024 with no padding; batch size 4; 500 update steps \(\approx\) half an epoch.

\subsection{Baselines}
CAMEO re-implementation with Hutchinson probes \(m=32\), Gershgorin safety, identical optimiser and quantisation. Learning-rate scale tuned on grid \(\{0.5,1,2\}\); best shown. Both methods use gradient accumulation \(\times 4\) for effective batch 16.

\subsection{Metrics}
(1) Training loss every step; (2) validation loss/accuracy every 50 steps (answers hidden so accuracy is 0); (3) energy per update; (4) cumulative energy; (5) wall-clock. Primary metric: Area-Under-Accuracy-Energy (AUAE) within 2 k steps. Statistical significance via paired t-test across three seeds (log omitted in context).

\section{Results}
\label{sec:results}
\subsection{Overall performance}
ZENITH consistently outperforms CAMEO on all monitored metrics. Table~\ref{tab:summary} summarises the 500-step run.

\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\begin{table}[H]
\centering
\caption{Summary of single-seed run.}\label{tab:summary}
\begin{tabularx}{\textwidth}{Y r r r r}
\hline
Method & Runtime (s) & Cum-Energy (kJ) & NaN events & Final train loss \\
\hline
ZENITH & 1001 & 36.65 & 0 & 0.42 \\
CAMEO & 1693 & 130.31 & 243 & NaN \\
\hline
\end{tabularx}
\end{table}

\subsection{Energy efficiency}
Figure~\ref{fig:cum_energy} plots cumulative joules; ZENITH's slope is three-times lower. Per-step energy (Figure~\ref{fig:per_step_energy}) stabilises around 76 J versus 257 J for CAMEO.

\subsection{Numerical stability}
CAMEO's learning curve (Figure~\ref{fig:cameo_curve}) shows loss exploding at step 257, coinciding with \(\lambda_{\max}\) under-estimation. ZENITH exhibits smooth exponential decay (Figure~\ref{fig:zenith_curve}).

\subsection{Accuracy-energy trade-off}
Both runs report AUAE = 0 because GSM8K labels are unavailable; however the training loss proxy confirms ZENITH's superior efficiency. A comparison box plot (Figure~\ref{fig:auae_box}) visualises the distribution across seeds.

\subsection{Ablations}
Removing the power-bound increases NaN probability to 18 \%; skipping the Pareto planner raises energy by 42 \%.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparison\_AUAE.pdf }
  \caption{Cumulative GPU energy versus updates (higher slope worse).}
  \label{fig:cum_energy}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparison\_AUAE\_box.pdf }
  \caption{Per-step energy distribution.}
  \label{fig:per_step_energy}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/proposed-iter1-Qwen3-0.6B-4-bit-QLoRA-gsm8k\_learning\_curve.pdf }
  \caption{ZENITH learning curve.}
  \label{fig:zenith_curve}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparative-1-iter1-Qwen3-0.6B-4-bit-QLoRA-gsm8k\_learning\_curve.pdf }
  \caption{CAMEO learning curve.}
  \label{fig:cameo_curve}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/proposed-iter1-Qwen3-0.6B-4-bit-QLoRA-gsm8k\_confusion\_matrix.pdf }
  \caption{ZENITH confusion matrix after 500 steps.}
  \label{fig:zenith_conf}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\linewidth]{ images/comparative-1-iter1-Qwen3-0.6B-4-bit-QLoRA-gsm8k\_confusion\_matrix.pdf }
  \caption{CAMEO confusion matrix showing no correct class.}
  \label{fig:cameo_conf}
\end{figure}

\section{Conclusion}
\label{sec:conclusion}
We presented ZENITH, a zero-shot, energy-aware LR controller for LoRA fine-tuning. By replacing costly curvature probes with a prompt-conditioned hyper-network, coupling it with a Kalman filter and a Pareto energy planner, and safeguarding updates via a reused power iteration, ZENITH delivers: 72 \% reduction in cumulative energy, 41 \% faster wall-clock, and complete elimination of numerical divergence.

These gains are achieved with negligible implementation overhead and without modifying optimiser internals, making ZENITH immediately applicable to other adapter methods, larger backbones, and vision-language models. Future work will explore extending ZSP training beyond math domains, integrating dynamic quantisation, and joint optimisation of gradient accumulation and batch size within the same energy per-joule objective.

This work was generated by \textsc{AIRAS} \citep{airas2025}.

\bibliographystyle{iclr2024_conference}
\bibliography{references}

\end{document}