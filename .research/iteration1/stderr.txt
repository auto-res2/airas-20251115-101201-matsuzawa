Using CPython 3.11.13
Creating virtual environment at: .venv
Resolved 112 packages in 126ms
Installed 103 packages in 4.58s
 + accelerate==1.11.0
 + aiohappyeyeballs==2.6.1
 + aiohttp==3.13.2
 + aiosignal==1.4.0
 + alembic==1.17.2
 + annotated-types==0.7.0
 + antlr4-python3-runtime==4.9.3
 + anyio==4.11.0
 + attrs==25.4.0
 + bitsandbytes==0.48.2
 + certifi==2025.11.12
 + charset-normalizer==3.4.4
 + click==8.3.0
 + colorlog==6.10.1
 + contourpy==1.3.3
 + cycler==0.12.1
 + datasets==4.4.1
 + dill==0.4.0
 + filelock==3.20.0
 + fonttools==4.60.1
 + frozenlist==1.8.0
 + fsspec==2025.10.0
 + gitdb==4.0.12
 + gitpython==3.1.45
 + greenlet==3.2.4
 + h11==0.16.0
 + hf-xet==1.2.0
 + httpcore==1.0.9
 + httpx==0.28.1
 + huggingface-hub==0.36.0
 + hydra-core==1.3.2
 + idna==3.11
 + jinja2==3.1.6
 + joblib==1.5.2
 + kiwisolver==1.4.9
 + mako==1.3.10
 + markupsafe==3.0.3
 + matplotlib==3.10.7
 + mpmath==1.3.0
 + multidict==6.7.0
 + multiprocess==0.70.18
 + networkx==3.5
 + numpy==2.3.4
 + nvidia-cublas-cu12==12.8.4.1
 + nvidia-cuda-cupti-cu12==12.8.90
 + nvidia-cuda-nvrtc-cu12==12.8.93
 + nvidia-cuda-runtime-cu12==12.8.90
 + nvidia-cudnn-cu12==9.10.2.21
 + nvidia-cufft-cu12==11.3.3.83
 + nvidia-cufile-cu12==1.13.1.3
 + nvidia-curand-cu12==10.3.9.90
 + nvidia-cusolver-cu12==11.7.3.90
 + nvidia-cusparse-cu12==12.5.8.93
 + nvidia-cusparselt-cu12==0.7.1
 + nvidia-ml-py==13.580.82
 + nvidia-nccl-cu12==2.27.5
 + nvidia-nvjitlink-cu12==12.8.93
 + nvidia-nvshmem-cu12==3.3.20
 + nvidia-nvtx-cu12==12.8.90
 + omegaconf==2.3.0
 + optuna==4.6.0
 + packaging==25.0
 + pandas==2.3.3
 + peft==0.18.0
 + pillow==12.0.0
 + platformdirs==4.5.0
 + propcache==0.4.1
 + protobuf==6.33.1
 + psutil==7.1.3
 + pyarrow==22.0.0
 + pydantic==2.12.4
 + pydantic-core==2.41.5
 + pynvml==13.0.1
 + pyparsing==3.2.5
 + python-dateutil==2.9.0.post0
 + pytz==2025.2
 + pyyaml==6.0.3
 + regex==2025.11.3
 + requests==2.32.5
 + safetensors==0.6.2
 + scikit-learn==1.7.2
 + scipy==1.16.3
 + seaborn==0.13.2
 + sentry-sdk==2.44.0
 + six==1.17.0
 + smmap==5.0.2
 + sniffio==1.3.1
 + sqlalchemy==2.0.44
 + sympy==1.14.0
 + threadpoolctl==3.6.0
 + tokenizers==0.22.1
 + torch==2.9.1
 + tqdm==4.67.1
 + transformers==4.57.1
 + triton==3.5.1
 + typing-extensions==4.15.0
 + typing-inspection==0.4.2
 + tzdata==2025.2
 + urllib3==2.5.0
 + wandb==0.23.0
 + xxhash==3.6.0
 + yarl==1.22.0
 + zenith-experiments==0.1.0 (from file:///home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa)
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/main.py:21: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/train.py:342: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 176609.99 examples/s]
Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 207287.16 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:00,  7.04 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:00<00:00, 13.73 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:00,  7.11 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:00<00:00, 13.70 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:02,  2.68 examples/s]Map (num_proc=4):  75%|███████▌  | 6/8 [00:00<00:00,  8.08 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:01<00:00,  6.25 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:02,  2.78 examples/s]Map (num_proc=4):  50%|█████     | 4/8 [00:00<00:00,  5.62 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:00<00:00, 10.83 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:01<00:00,  6.29 examples/s]
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/train.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=cfg.training.bf16)
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/train.py:413: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=cfg.training.bf16):
Using CPython 3.11.13
Creating virtual environment at: .venv
Resolved 112 packages in 97ms
Installed 103 packages in 4.80s
 + accelerate==1.11.0
 + aiohappyeyeballs==2.6.1
 + aiohttp==3.13.2
 + aiosignal==1.4.0
 + alembic==1.17.2
 + annotated-types==0.7.0
 + antlr4-python3-runtime==4.9.3
 + anyio==4.11.0
 + attrs==25.4.0
 + bitsandbytes==0.48.2
 + certifi==2025.11.12
 + charset-normalizer==3.4.4
 + click==8.3.0
 + colorlog==6.10.1
 + contourpy==1.3.3
 + cycler==0.12.1
 + datasets==4.4.1
 + dill==0.4.0
 + filelock==3.20.0
 + fonttools==4.60.1
 + frozenlist==1.8.0
 + fsspec==2025.10.0
 + gitdb==4.0.12
 + gitpython==3.1.45
 + greenlet==3.2.4
 + h11==0.16.0
 + hf-xet==1.2.0
 + httpcore==1.0.9
 + httpx==0.28.1
 + huggingface-hub==0.36.0
 + hydra-core==1.3.2
 + idna==3.11
 + jinja2==3.1.6
 + joblib==1.5.2
 + kiwisolver==1.4.9
 + mako==1.3.10
 + markupsafe==3.0.3
 + matplotlib==3.10.7
 + mpmath==1.3.0
 + multidict==6.7.0
 + multiprocess==0.70.18
 + networkx==3.5
 + numpy==2.3.4
 + nvidia-cublas-cu12==12.8.4.1
 + nvidia-cuda-cupti-cu12==12.8.90
 + nvidia-cuda-nvrtc-cu12==12.8.93
 + nvidia-cuda-runtime-cu12==12.8.90
 + nvidia-cudnn-cu12==9.10.2.21
 + nvidia-cufft-cu12==11.3.3.83
 + nvidia-cufile-cu12==1.13.1.3
 + nvidia-curand-cu12==10.3.9.90
 + nvidia-cusolver-cu12==11.7.3.90
 + nvidia-cusparse-cu12==12.5.8.93
 + nvidia-cusparselt-cu12==0.7.1
 + nvidia-ml-py==13.580.82
 + nvidia-nccl-cu12==2.27.5
 + nvidia-nvjitlink-cu12==12.8.93
 + nvidia-nvshmem-cu12==3.3.20
 + nvidia-nvtx-cu12==12.8.90
 + omegaconf==2.3.0
 + optuna==4.6.0
 + packaging==25.0
 + pandas==2.3.3
 + peft==0.18.0
 + pillow==12.0.0
 + platformdirs==4.5.0
 + propcache==0.4.1
 + protobuf==6.33.1
 + psutil==7.1.3
 + pyarrow==22.0.0
 + pydantic==2.12.4
 + pydantic-core==2.41.5
 + pynvml==13.0.1
 + pyparsing==3.2.5
 + python-dateutil==2.9.0.post0
 + pytz==2025.2
 + pyyaml==6.0.3
 + regex==2025.11.3
 + requests==2.32.5
 + safetensors==0.6.2
 + scikit-learn==1.7.2
 + scipy==1.16.3
 + seaborn==0.13.2
 + sentry-sdk==2.44.0
 + six==1.17.0
 + smmap==5.0.2
 + sniffio==1.3.1
 + sqlalchemy==2.0.44
 + sympy==1.14.0
 + threadpoolctl==3.6.0
 + tokenizers==0.22.1
 + torch==2.9.1
 + tqdm==4.67.1
 + transformers==4.57.1
 + triton==3.5.1
 + typing-extensions==4.15.0
 + typing-inspection==0.4.2
 + tzdata==2025.2
 + urllib3==2.5.0
 + wandb==0.23.0
 + xxhash==3.6.0
 + yarl==1.22.0
 + zenith-experiments==0.1.0 (from file:///home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa)
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/main.py:21: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/train.py:342: UserWarning: 
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  @hydra.main(config_path="../config", config_name="config")
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/.venv/lib/python3.11/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.
See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.
  ret = run_job(
Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]Generating train split: 100%|██████████| 7473/7473 [00:00<00:00, 180340.23 examples/s]
Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1319/1319 [00:00<00:00, 209152.28 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:00,  7.32 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:00<00:00, 14.17 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:00,  8.03 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:00<00:00, 15.18 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:02,  2.87 examples/s]Map (num_proc=4):  75%|███████▌  | 6/8 [00:00<00:00,  8.21 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:01<00:00,  6.54 examples/s]
Map (num_proc=4):   0%|          | 0/8 [00:00<?, ? examples/s]Map (num_proc=4):  25%|██▌       | 2/8 [00:00<00:02,  2.79 examples/s]Map (num_proc=4):  75%|███████▌  | 6/8 [00:00<00:00,  7.70 examples/s]Map (num_proc=4): 100%|██████████| 8/8 [00:01<00:00,  6.37 examples/s]
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/train.py:391: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=cfg.training.bf16)
/home/toma/t-80-8-b-03/_work/airas-20251115-101201-matsuzawa/airas-20251115-101201-matsuzawa/src/train.py:413: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=cfg.training.bf16):
